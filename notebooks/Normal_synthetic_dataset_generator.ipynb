{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bo-EXnyyIfK9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IHtdsBzYLrNK"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from pandas.core.resample import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==1.4.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPI = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bLq8H00dArQ1"
   },
   "outputs": [],
   "source": [
    "path = '../new_normal_data_500/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1NBICxSGsPIP"
   },
   "outputs": [],
   "source": [
    "folder = \"SyntheticDataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-FU1wbsgvKzV"
   },
   "outputs": [],
   "source": [
    "dropouts = [0, 0, 0] # non rad, rad, semi-rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ev8OZUKd7Nn8"
   },
   "outputs": [],
   "source": [
    "def show_interactions_plots(true_util, users_pop1, users_pop3, users_pop2, items_pop1, items_pop2, ETA, saving_path):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    params = {\n",
    "    'figure.dpi':DPI,\n",
    "    \"text.usetex\": True,\n",
    "    'legend.title_fontsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'axes.labelsize': 22,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Computer Modern Sans Serif\",\n",
    "    }\n",
    "\n",
    "    \n",
    "    sns.reset_orig()\n",
    "    mpl.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.imshow(true_util[np.concatenate([users_pop1, users_pop3, users_pop2])][:, np.concatenate([items_pop1, items_pop2])].T,\n",
    "               interpolation='nearest', aspect='auto',\n",
    "               cmap='Greens')\n",
    "    \n",
    "#     if ETA == 0.5:\n",
    "#         plt.colorbar().set_label(label='Utility', size=21)\n",
    "#     plt.title(f'Utilities (Î·: {ETA})', fontsize=28)\n",
    "    plt.yticks(np.arange(0, 10001, 2500))\n",
    "    plt.xlabel('Users', fontsize=40)\n",
    "    \n",
    "#     if ETA == 0.1:\n",
    "    plt.ylabel('Items', fontsize=40)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(saving_path + f'Utilities_eta_{ETA}.png', dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TrDsJAHb1p6M"
   },
   "outputs": [],
   "source": [
    "def print_harmful_neutral_percentages(new_df):\n",
    "\n",
    "    users_categories = ['non radicalized', 'radicalized', 'semi-radicalized']\n",
    "\n",
    "    for cat in users_categories:\n",
    "\n",
    "        temp_df = new_df[new_df['Orientation'] == cat].groupby('User')\n",
    "\n",
    "        harmful_percentages = []\n",
    "        neutral_percentages = []\n",
    "        for _, user_temp_df in temp_df:\n",
    "            harmful_perc = len(user_temp_df[user_temp_df['Label'] == 'harmful']['Video'].unique(\n",
    "            )) / len(user_temp_df['Video'].unique())\n",
    "            neutral_perc = len(user_temp_df[user_temp_df['Label'] == 'neutral']['Video'].unique(\n",
    "            )) / len(user_temp_df['Video'].unique())\n",
    "\n",
    "            harmful_percentages.append(harmful_perc)\n",
    "            neutral_percentages.append(neutral_perc)\n",
    "\n",
    "        harmful_percentages = np.array(harmful_percentages)\n",
    "        counts, bins = np.histogram(harmful_percentages)\n",
    "        \n",
    "        #plt.figure(figsize=(10, 10))\n",
    "        plt.stairs(counts, bins)\n",
    "        #plt.show()\n",
    "\n",
    "        neutral_percentages = np.array(neutral_percentages)\n",
    "\n",
    "        print(\"Category\", cat)\n",
    "        print(\"harmful percentages\")\n",
    "        print(\"Mean: {}, Dev Stand {}\".format(\n",
    "            np.mean(harmful_percentages), np.std(harmful_percentages)))\n",
    "        print(\"neutral percentages\")\n",
    "        print(\"Mean: {}, Dev Stand {}\\n\".format(\n",
    "            np.mean(neutral_percentages), np.std(neutral_percentages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_num_items(eta, num_items):\n",
    "    path = \"New_Normal_Statistics/num_items_distributions_500.tsv\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        f = open(path, \"w\")\n",
    "        f.write(\"ETA\\tNUM_ITEMS\\n\")\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    f = open(path, \"a\")\n",
    "    f.write(\"{}\\t{}\\n\".format(eta, num_items))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gHXVQSd-URwl"
   },
   "outputs": [],
   "source": [
    "def fix_top_k_items(sorted_items, history_length, items_to_add, items_list):\n",
    "\n",
    "    top_k_items = list(sorted_items[-history_length:]) # highest preferences score\n",
    "    #print(\"topk items\", top_k_items)\n",
    "\n",
    "    reverse_sorted_top_k_items = top_k_items.copy()\n",
    "    reverse_sorted_top_k_items.reverse()\n",
    "\n",
    "    removed_items = 0\n",
    "\n",
    "    for i in reverse_sorted_top_k_items:\n",
    "\n",
    "        if removed_items == items_to_add:\n",
    "            break\n",
    "\n",
    "        if i not in items_list:\n",
    "            removed_items += 1\n",
    "            top_k_items.remove(i)\n",
    "    \n",
    "    #print(\"topk after remove\", top_k_items)\n",
    "    \n",
    "    further_sorted_items = sorted_items[history_length:]\n",
    "    \n",
    "    #print(\"further sorted\", further_sorted_items)\n",
    "\n",
    "    for i in further_sorted_items:\n",
    "\n",
    "        if len(top_k_items) == history_length:\n",
    "            break\n",
    "\n",
    "        if i in items_list:\n",
    "            top_k_items.append(i)\n",
    "\n",
    "    return np.array(top_k_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SzJSIYCjOq-x"
   },
   "outputs": [],
   "source": [
    "def check_semi_radicalized(original_top_k_items, sorted_items, history_length, harmful_items, neutral_items):\n",
    "\n",
    "    min_harmful_percentage = 0.2\n",
    "    max_harmful_percentage = 0.8\n",
    "\n",
    "    harmful_count = 0\n",
    "\n",
    "    for item in original_top_k_items:\n",
    "\n",
    "        if item in harmful_items:\n",
    "            harmful_count += 1\n",
    "            \n",
    "    harmful_percentage = round(harmful_count/history_length, 2)\n",
    "\n",
    "    if harmful_percentage >= min_harmful_percentage and harmful_percentage <= max_harmful_percentage:\n",
    "        # print(\"Semi-radicalized are okay\")\n",
    "        # print(\"Harmful percentage is\", harmful_percentage)\n",
    "        return original_top_k_items\n",
    "\n",
    "    # print(\"Something is wrong with semi-radicalized\")\n",
    "    # print(\"Harmful percentage is\", harmful_percentage)\n",
    "\n",
    "    if harmful_percentage < min_harmful_percentage:  # we want more harmful items\n",
    "        harmful_items_to_add = round(\n",
    "            min_harmful_percentage*history_length - harmful_percentage * history_length)\n",
    "\n",
    "        new_top_k_items = fix_top_k_items(\n",
    "            sorted_items, history_length, harmful_items_to_add, harmful_items)\n",
    "\n",
    "    # we want less harmful items (more neutral)\n",
    "    elif harmful_percentage > max_harmful_percentage:\n",
    "        neutral_items_to_add = round(\n",
    "            abs(max_harmful_percentage*history_length - harmful_percentage * history_length))\n",
    "\n",
    "        new_top_k_items = fix_top_k_items(\n",
    "            sorted_items, history_length, neutral_items_to_add, neutral_items)\n",
    "\n",
    "    return new_top_k_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uR__g720ommy"
   },
   "outputs": [],
   "source": [
    "def generate_samples(num_users, num_attrs, sim_index, users_params_prefs, items_params_attrs, items_slants, ETA=None):\n",
    "\n",
    "    non_rad_parameter_prefs, rad_users_parameter_prefs, semi_rad_users_parameter_prefs = users_params_prefs\n",
    "    harmful_items_parameter_attrs, neutral_items_parameter_attrs = items_params_attrs\n",
    "    harmful_items_slants, neutral_items_slants = items_slants\n",
    "\n",
    "    mu_history_lengths = [80, 80, 80]  # non rad, rad, semi-rad\n",
    "    sigma_history_lengths = [10, 10, 10]\n",
    "\n",
    "    dataset_path = path + folder + \\\n",
    "        'History_{}_{}/'.format(mu_history_lengths[0],\n",
    "                                sigma_history_lengths[0])\n",
    "\n",
    "    if not exists(dataset_path):\n",
    "        os.makedirs(dataset_path)\n",
    "\n",
    "    # starting eta 0.1, we will generate 9 datasets, each of them with different eta values\n",
    "    # from 0.1 to 0.9 (eta is the proportion of semi radicalized users in the dataset)\n",
    "\n",
    "    if ETA is None:\n",
    "        ETA = (0.6, 0.3, 0.1) # non rad, semi rad, rad\n",
    "\n",
    "    # constant parameter for Beta distribution (assumption 4)\n",
    "    mu_eta = 0.98\n",
    "\n",
    "    while ETA[0] < 1.0:\n",
    "\n",
    "        # generation populations according to eta\n",
    "        users_pop3 = np.random.permutation(range(num_users))[:int(num_users*ETA[1])]\n",
    "        tmp = np.delete(range(num_users), users_pop3)\n",
    "        users_pop2_idxs = np.random.permutation(range(len(tmp)))[:int(num_users*ETA[2])]\n",
    "        users_pop2 = tmp[users_pop2_idxs]\n",
    "        users_pop1 = np.delete(tmp, users_pop2_idxs)\n",
    "#         users_pop2_idxs = np.random.permutation(range(len(tmp)))[:len(tmp)//2]\n",
    "#         users_pop2 = tmp[users_pop2_idxs]\n",
    "#         users_pop1 = np.delete(tmp, users_pop2_idxs)\n",
    "\n",
    "        # generation users preferences rho_u (equation 3)\n",
    "        non_rad_users_prefs = rng.dirichlet(\n",
    "            non_rad_users_parameter_prefs[sim_index, :]+EPSILON, size=len(users_pop1))\n",
    "        rad_users_prefs = rng.dirichlet(\n",
    "            rad_users_parameter_prefs[sim_index, :]+EPSILON, size=len(users_pop2))\n",
    "        \n",
    "        semi_rad_users_prefs = rng.dirichlet(\n",
    "            semi_rad_users_parameter_prefs[sim_index, :]+EPSILON, size=len(users_pop3))\n",
    "        \n",
    "        user_prefs = np.zeros((num_users, num_attrs))\n",
    "\n",
    "        user_prefs[users_pop1] = non_rad_users_prefs\n",
    "        user_prefs[users_pop2] = rad_users_prefs\n",
    "        user_prefs[users_pop3] = semi_rad_users_prefs\n",
    "        \n",
    "        # items generation\n",
    "        items_pop1 = np.random.permutation(range(num_items))[:num_items//2]\n",
    "        items_pop2 = np.delete(range(num_items), items_pop1)\n",
    "\n",
    "        items = np.concatenate((items_pop1, items_pop2))\n",
    "\n",
    "        # generation items attributes (equation 3)\n",
    "        harmful_item_attrs = rng.dirichlet(\n",
    "            harmful_items_parameter_attrs[sim_index, :]+EPSILON, size=len(items_pop1))\n",
    "        neutral_item_attrs = rng.dirichlet(\n",
    "            neutral_items_parameter_attrs[sim_index, :]+EPSILON, size=len(items_pop2))\n",
    "\n",
    "        item_attrs = np.zeros((num_items, num_attrs))\n",
    "\n",
    "        item_attrs[items_pop1] = harmful_item_attrs\n",
    "        item_attrs[items_pop2] = neutral_item_attrs\n",
    "\n",
    "        # parameter to generate true utils using Beta distribution\n",
    "        true_utils_mu = user_prefs @ item_attrs.T\n",
    "      \n",
    "        true_utils_mu = np.clip(true_utils_mu, 1e-9, None)\n",
    "\n",
    "        # sample total utility from a Beta distribution (equation 2)\n",
    "        alphas, betas = mu_sigma_to_alpha_beta(true_utils_mu, sigma)\n",
    "        \n",
    "        #indexes = rng.choice(len(users_pop3), size=int(len(users_pop3)*0.7), replace=False)\n",
    "        #alphas[users_pop3[indexes]] = 5\n",
    "        #betas[users_pop3[indexes]] = 8.\n",
    "        alphas[users_pop3] = 10\n",
    "        betas[users_pop3] = 10.\n",
    "\n",
    "        true_util = rng.beta(alphas, betas, size=(num_users, num_items))\n",
    "\n",
    "        # generating noisy factor eta (assumption 4)\n",
    "        eta_alphas, eta_betas = mu_sigma_to_alpha_beta(mu_eta, sigma)\n",
    "        eta_users = rng.beta(eta_alphas, eta_betas,\n",
    "                             size=(num_users, num_items))\n",
    "\n",
    "        # users noisy preferences p_users (equation 4)\n",
    "        p_users = eta_users * true_util\n",
    "        \n",
    "        ETA = str(ETA).replace(\"(\", \"\").replace(\")\", \"\").replace(\", \", \"_\")\n",
    "\n",
    "        saving_path = dataset_path + f\"Eta_{ETA}/\"\n",
    "\n",
    "        if np.any(dropouts):  # there is some sparsity factor\n",
    "            new_folder_name = \"Sparsity_factor_\" + \\\n",
    "                str(dropouts).replace(\"[\", \"\").replace(\"]\", \"\").replace(\n",
    "                    \" \", \"\").replace(\",\", \"_\")\n",
    "            saving_path = saving_path + '{}/'.format(new_folder_name)\n",
    "\n",
    "        if not exists(saving_path):\n",
    "            os.makedirs(saving_path)\n",
    "            \n",
    "        print(saving_path)\n",
    "        true_util_df = pd.DataFrame(true_util)\n",
    "#         true_util_df.to_csv(saving_path + f\"True_util_eta_{ETA}.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "        #show_interactions_plots(true_util, users_pop1, users_pop3, users_pop2, items_pop1, items_pop2, ETA, saving_path)\n",
    "\n",
    "        interactions = []\n",
    "\n",
    "        # generating interactions per user (equation 5)\n",
    "\n",
    "        non_rad_history_lengths = 0\n",
    "        items_count = 0\n",
    "        \n",
    "        user_embeddings = []\n",
    "        item_embeddings = []\n",
    "        item_visited = []\n",
    "\n",
    "        for i in range(num_users):\n",
    "\n",
    "            top_k_indices = [-1]*num_items\n",
    "            ideal_rec_ranking = np.argsort(true_util[i])[::-1]\n",
    "\n",
    "            for j, elem in enumerate(ideal_rec_ranking):\n",
    "                top_k_indices[elem] = j+1\n",
    "\n",
    "            top_k_indices = np.array(top_k_indices)\n",
    "            top_k_indices = top_k_indices * p_users[i]\n",
    "\n",
    "            # campioniamo history length da una normale N([20]*num_users_categories, [3]*num_users_categories)\n",
    "\n",
    "            history_lengths = [max(sigma_history_lengths[k]*(1. - dropouts[k]),\n",
    "                                   np.random.normal(mu_history_lengths[k]*(1. - dropouts[k]), sigma_history_lengths[k]*(1. - dropouts[k]), 1)[0])\n",
    "                               for k in range(len(sigma_history_lengths))]\n",
    "\n",
    "            if i in users_pop1:\n",
    "                orientation = 'non radicalized'\n",
    "                history_length = history_lengths[0]\n",
    "\n",
    "            elif i in users_pop2:\n",
    "                orientation = 'radicalized'\n",
    "                history_length = history_lengths[1]\n",
    "\n",
    "            else:\n",
    "                orientation = 'semi-radicalized'\n",
    "                history_length = history_lengths[2]\n",
    "\n",
    "            history_length = round(history_length)\n",
    "            \n",
    "            top_k_items = np.argsort(top_k_indices)[-history_length:] # top-k items (highest preferences score)\n",
    "\n",
    "            #if orientation == \"semi-radicalized\":\n",
    "            #    top_k_items = check_semi_radicalized(top_k_items, np.argsort(\n",
    "            #        top_k_indices), history_length, items_pop1, items_pop2)\n",
    "            #    _ = check_semi_radicalized(top_k_items, np.argsort(\n",
    "            #        top_k_indices), history_length, items_pop1, items_pop2)\n",
    "            \n",
    "            user_embedding = user_prefs[i]\n",
    "            user_embeddings.append((i, user_embedding))\n",
    "                        \n",
    "            for item in top_k_items:\n",
    "                if item in items_pop1:\n",
    "                    label = \"harmful\"\n",
    "                    item_index = list(items_pop1).index(item)\n",
    "                    slant = harmful_items_slants[item_index]\n",
    "                else:\n",
    "                    label = \"neutral\"\n",
    "                    item_index = list(items_pop2).index(item)\n",
    "                    slant = neutral_items_slants[item_index]\n",
    "                    \n",
    "                item_embedding = item_attrs[item]\n",
    "                    \n",
    "                slant = round(slant, 2)\n",
    "                interactions.append((i, item, orientation, slant, label))\n",
    "                \n",
    "                if item not in item_visited:\n",
    "                    item_visited.append(item)\n",
    "                    item_embeddings.append((item, item_embedding))\n",
    "                \n",
    "        users_embeddings_fn = \"Users_embeddings\"\n",
    "        items_embeddings_fn = \"Items_embeddings\"\n",
    "        \n",
    "        np.save(saving_path + users_embeddings_fn, user_embeddings)\n",
    "        np.save(saving_path + items_embeddings_fn, item_embeddings)\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            columns=[\"User\", \"Video\", \"Orientation\", \"Slant\", \"Label\"], data=interactions)\n",
    "        \n",
    "        print(f\"Num users {len(df['User'].unique())}\")\n",
    "        print(f\"Num items {len(df['Video'].unique())}\")\n",
    "        \n",
    "        write_num_items(ETA, len(df['Video'].unique()))\n",
    "        \n",
    "        #print_harmful_neutral_percentages(df)\n",
    "\n",
    "        df.to_csv(saving_path +\n",
    "                   f'Histories_eta_{ETA}.tsv', index=False, sep=\"\\t\")\n",
    "\n",
    "        to_print = \"Processing ETA \" + str(ETA)\n",
    "        if np.any(dropouts):\n",
    "            to_print += \" with sparsity factor \" + str(dropouts)\n",
    "\n",
    "        print(to_print)\n",
    "\n",
    "#         ETA = round(ETA + 0.1, 2)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v7_3Z5tgDtRK"
   },
   "outputs": [],
   "source": [
    "def mu_sigma_to_alpha_beta(mu, sigma):\n",
    "    \"\"\" For Chaney's custom Beta' function, we convert\n",
    "        a mean and variance to an alpha and beta parameter\n",
    "        of a Beta function. See footnote 3 page 3 of Chaney\n",
    "        et al. for details.\n",
    "    \"\"\"\n",
    "    alpha = ((1-mu) / (sigma**2) - (1/mu)) * mu**2\n",
    "    beta = alpha * (1/mu - 1)\n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "'''\n",
    "Procedimento del paper di Chaney con una modifica per generare le nostre tre popolazioni di riferimento 1. non rad, 2.semi-rad e 3. rad con una %variabile di semi-rad \\eta.\n",
    "Per produrre la generazione delle interazioni usiamo la loro formula in Equazione (5), considerando come funzione di ranking ciÃ² che loro chiamano âidealâ e per ogni utente generiamo 20 interazioni.\n",
    "Generiamo tanti datasets con valori di \\eta in (0,1) con step di 0.1 (quindi 9 dataset) e applichiamo la nostra procedura.\n",
    "Considerando che ci sono 100 utenti e 10000 items dovrebbe essere molto veloce.\n",
    "'''\n",
    "\n",
    "sigma = 1e-5\n",
    "\n",
    "rng = np.random.default_rng(12121995)\n",
    "num_attrs = 20  # K\n",
    "num_sims = 1\n",
    "\n",
    "sim_index = 0\n",
    "num_users = 500 # 100\n",
    "num_items = 10000 # 10000\n",
    "\n",
    "# generation users mu_rho parameter for generating user preferences (equation 3)\n",
    "# value to obtain in average ~4% harmful items and ~96% neutral items (viceversa for radicalized users)\n",
    "EPSILON = 0.00035\n",
    "\n",
    "non_rad_params = np.ones(num_attrs) # non-rad users\n",
    "non_rad_params[num_attrs//2:] = EPSILON\n",
    "non_rad_users_parameter_prefs = rng.dirichlet(non_rad_params, size=num_sims) * 10\n",
    "\n",
    "\n",
    "rad_params = np.ones(num_attrs) # rad users\n",
    "rad_params[:num_attrs//2] = EPSILON \n",
    "rad_users_parameter_prefs = rng.dirichlet(rad_params, size=num_sims) * 10\n",
    "\n",
    "semi_params = np.ones(num_attrs) # semi-rad users\n",
    "semi_rad_users_parameter_prefs = rng.dirichlet(\n",
    "    semi_params, size=num_sims) * 10\n",
    "\n",
    "# generation items mu_alpha parameter for generating item attributes (equation 3)\n",
    "harmful_items_params = np.ones(num_attrs) * 100\n",
    "harmful_items_params[:num_attrs//2] = EPSILON\n",
    "harmful_items_parameter_attrs = rng.dirichlet(\n",
    "    harmful_items_params, size=num_sims) * 0.1\n",
    "\n",
    "neutral_items_params = np.ones(num_attrs) * 100\n",
    "neutral_items_params[num_attrs//2:] = EPSILON\n",
    "neutral_items_parameter_attrs = rng.dirichlet(\n",
    "    neutral_items_params, size=num_sims) * 0.1\n",
    "\n",
    "\n",
    "# items slants generation\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "harmful_items_slants = np.random.uniform(low=.75, high=1., size=num_items//2)\n",
    "neutral_items_slants = np.random.uniform(low=0., high=.25, size=num_items//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.65, 0.2, 0.15)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.65_0.2_0.15/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 7320\n",
      "Processing ETA 0.65_0.2_0.15\n",
      "(0.7, 0.2, 0.1)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.7_0.2_0.1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 7225\n",
      "Processing ETA 0.7_0.2_0.1\n",
      "(0.75, 0.2, 0.05)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.75_0.2_0.05/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 7175\n",
      "Processing ETA 0.75_0.2_0.05\n",
      "(0.79, 0.2, 0.01)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.79_0.2_0.01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 6955\n",
      "Processing ETA 0.79_0.2_0.01\n",
      "(0.45, 0.4, 0.15)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.45_0.4_0.15/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 8741\n",
      "Processing ETA 0.45_0.4_0.15\n",
      "(0.5, 0.4, 0.1)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.5_0.4_0.1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 8733\n",
      "Processing ETA 0.5_0.4_0.1\n",
      "(0.55, 0.4, 0.05)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.55_0.4_0.05/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 8704\n",
      "Processing ETA 0.55_0.4_0.05\n",
      "(0.59, 0.4, 0.01)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.59_0.4_0.01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 8487\n",
      "Processing ETA 0.59_0.4_0.01\n",
      "(0.25, 0.6, 0.15)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.25_0.6_0.15/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 9428\n",
      "Processing ETA 0.25_0.6_0.15\n",
      "(0.3, 0.6, 0.1)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.3_0.6_0.1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 9447\n",
      "Processing ETA 0.3_0.6_0.1\n",
      "(0.35, 0.6, 0.05)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.35_0.6_0.05/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 9396\n",
      "Processing ETA 0.35_0.6_0.05\n",
      "(0.39, 0.6, 0.01)\n",
      "../new_normal_data_500/processed/SyntheticDataset/History_80_10/Eta_0.39_0.6_0.01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/coppolillo/AlgorithmicDrift/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users 500\n",
      "Num items 9384\n",
      "Processing ETA 0.39_0.6_0.01\n"
     ]
    }
   ],
   "source": [
    "list_ETA = [(0.65, 0.2, 0.15), (0.7, 0.2, 0.1), (0.75, 0.2, 0.05), (0.79, 0.2, 0.01),\n",
    "            (0.45, 0.4, 0.15), (0.5, 0.4, 0.1), (0.55, 0.4, 0.05), (0.59, 0.4, 0.01),\n",
    "            (0.25, 0.6, 0.15), (0.3, 0.6, 0.1), (0.35, 0.6, 0.05), (0.39, 0.6, 0.01)]\n",
    "\n",
    "\n",
    "for ETA in list_ETA:\n",
    "    print(ETA)\n",
    "    users_params_prefs = (non_rad_users_parameter_prefs,\n",
    "                          rad_users_parameter_prefs, semi_rad_users_parameter_prefs)\n",
    "    items_params_attrs = (harmful_items_parameter_attrs,\n",
    "                          neutral_items_parameter_attrs)\n",
    "    items_slants = (harmful_items_slants, neutral_items_slants)\n",
    "\n",
    "    #ETA = (0.5, 0.4, 0.1)\n",
    "\n",
    "    sum_ETA = ETA[0] + ETA[1] + ETA[2]\n",
    "\n",
    "    if False:#sum_ETA != 1.:\n",
    "        print(sum_ETA)\n",
    "        print(\"ETA does not equal 1\")\n",
    "\n",
    "    else:\n",
    "        generate_samples(num_users, num_attrs, sim_index,\n",
    "                         users_params_prefs, items_params_attrs, items_slants, ETA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Synthetic_dataset_generator.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
